{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d448e5",
   "metadata": {},
   "source": [
    "# Partie 1 : Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36951246",
   "metadata": {},
   "source": [
    "1-Nettoyage des données\n",
    "a- Visualisation des propriétés de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de260611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          B\n",
      "A  count  1    1.0\n",
      "          2    2.0\n",
      "          3    1.0\n",
      "          4    1.0\n",
      "          5    2.0\n",
      "              ... \n",
      "C  max    1    5.0\n",
      "          2    3.0\n",
      "          3    4.0\n",
      "          4    1.0\n",
      "          5    3.0\n",
      "Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [0,0,0,0,0,1,1],\n",
    " 'B': [1,2,3,5,4,2,5],\n",
    " 'C': [5,3,4,1,1,2,3]})\n",
    "# Groupement des données en fonction de la colonne 'B' et application de la méthode describe pour obtenir des statistiques descriptives\n",
    "a_group_desc = df.groupby('B').describe()\n",
    "# Réorganisation des données pour une meilleure visualisation à l'aide de la méthode unstack\n",
    "unstacked = a_group_desc.unstack()\n",
    "print(unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d19f1",
   "metadata": {},
   "source": [
    "b- Détection et suppression des données redondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c50280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : \n",
      "\n",
      "     brand style  rating\n",
      "0  Yum Yum   cup     4.0\n",
      "1  Yum Yum   cup     4.0\n",
      "2  Indomie   cup     3.5\n",
      "3  Indomie  pack    15.0\n",
      "4  Indomie  pack     5.0\n",
      "\n",
      " Les données doublons : \n",
      "\n",
      "1    True\n",
      "dtype: bool\n",
      "1\n",
      "\n",
      " Après suppression des données doublons : \n",
      "\n",
      "     brand style  rating\n",
      "0  Yum Yum   cup     4.0\n",
      "2  Indomie   cup     3.5\n",
      "3  Indomie  pack    15.0\n",
      "4  Indomie  pack     5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, 3.5, 15, 5]\n",
    "})\n",
    "# Recherche des données en double dans le DataFrame\n",
    "search = df.duplicated()\n",
    "print(\"Data : \\n\")\n",
    "print(df)\n",
    "    # Affichage des données en double dans le DataFrame\n",
    "print(\"\\n Les données doublons : \\n\")\n",
    "print(search[search == True])\n",
    "#Affichage du nombre de lignes en double dans le DataFrame\n",
    "print(search.sum())\n",
    "#Suppression des lignes en double dans le DataFrame\n",
    "print(\"\\n Après suppression des données doublons : \\n\")\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(df_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f703b1",
   "metadata": {},
   "source": [
    "c- Détection et traitement des données manquantes (missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77ae11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2a403d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualiser les données manquantes :\n",
      "   brand  style  rating\n",
      "0  False  False   False\n",
      "1  False   True   False\n",
      "2  False  False    True\n",
      "3  False  False   False\n",
      "4   True  False   False\n",
      "\n",
      "Isoler les données manquantes :\n",
      "     brand style  rating\n",
      "1  Yum Yum  None     4.0\n",
      "2  Indomie   cup     NaN\n",
      "4     None  pack     5.0\n",
      "\n",
      "Nombre de données manquantes par colonne :\n",
      "brand     1\n",
      "style     1\n",
      "rating    1\n",
      "dtype: int64\n",
      "Nombre total de données manquantes : 3\n",
      "\n",
      "Après le remplacement des données manquantes par la moyenne :\n",
      "     brand style  rating\n",
      "0  Yum Yum   cup     4.0\n",
      "1  Yum Yum  None     4.0\n",
      "2  Indomie   cup     7.0\n",
      "3  Indomie  pack    15.0\n",
      "4     None  pack     5.0\n",
      "\n",
      "Après la suppression des données manquantes :\n",
      "     brand style  rating\n",
      "0  Yum Yum   cup     4.0\n",
      "2  Indomie   cup     7.0\n",
      "3  Indomie  pack    15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Création des DataFrames d'exemple\n",
    "s = pd.DataFrame([1, 2, 3, np.NaN, 5, 6, None])\n",
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', None],\n",
    "    'style': ['cup', None, 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, np.NaN, 15, 5]\n",
    "})\n",
    "\n",
    "# Visualisation des données manquantes\n",
    "print(\"Visualiser les données manquantes :\")\n",
    "print(df.isnull())\n",
    "\n",
    "# Isoler les données manquantes\n",
    "print(\"\\nIsoler les données manquantes :\")\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "\n",
    "# Nombre de données manquantes par colonne et au total\n",
    "print(\"\\nNombre de données manquantes par colonne :\")\n",
    "print(df.isnull().sum())\n",
    "print(\"Nombre total de données manquantes :\", df.isnull().values.sum())\n",
    "\n",
    "# Remplacement des données manquantes par la moyenne\n",
    "df['rating'] = df['rating'].fillna(df['rating'].mean())\n",
    "print(\"\\nAprès le remplacement des données manquantes par la moyenne :\")\n",
    "print(df)\n",
    "\n",
    "# Suppression des données manquantes\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nAprès la suppression des données manquantes :\")\n",
    "print(df_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae78fadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/8e/45/1d6c34f0a4db820968e35ca872e2a553f4d1015e7437f04128496c046034/scikit_learn-1.3.1-cp38-cp38-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.1-cp38-cp38-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\mouna\\anaconda3\\envs\\atelier_ml\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "     ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/42.2 MB 487.6 kB/s eta 0:01:27\n",
      "     --------------------------------------- 0.1/42.2 MB 751.6 kB/s eta 0:00:57\n",
      "     --------------------------------------- 0.2/42.2 MB 952.6 kB/s eta 0:00:45\n",
      "     ---------------------------------------- 0.2/42.2 MB 1.0 MB/s eta 0:00:41\n",
      "     ---------------------------------------- 0.2/42.2 MB 1.0 MB/s eta 0:00:41\n",
      "     ---------------------------------------- 0.3/42.2 MB 1.0 MB/s eta 0:00:42\n",
      "     ---------------------------------------- 0.3/42.2 MB 1.0 MB/s eta 0:00:42\n",
      "     --------------------------------------- 0.4/42.2 MB 916.6 kB/s eta 0:00:46\n",
      "     --------------------------------------- 0.4/42.2 MB 981.9 kB/s eta 0:00:43\n",
      "     ---------------------------------------- 0.5/42.2 MB 1.1 MB/s eta 0:00:40\n",
      "      --------------------------------------- 0.6/42.2 MB 1.1 MB/s eta 0:00:38\n",
      "      --------------------------------------- 0.7/42.2 MB 1.1 MB/s eta 0:00:37\n",
      "      --------------------------------------- 0.7/42.2 MB 1.2 MB/s eta 0:00:36\n",
      "      --------------------------------------- 0.8/42.2 MB 1.2 MB/s eta 0:00:35\n",
      "      --------------------------------------- 0.9/42.2 MB 1.2 MB/s eta 0:00:35\n",
      "      --------------------------------------- 1.0/42.2 MB 1.2 MB/s eta 0:00:34\n",
      "      --------------------------------------- 1.0/42.2 MB 1.2 MB/s eta 0:00:34\n",
      "     - -------------------------------------- 1.1/42.2 MB 1.3 MB/s eta 0:00:33\n",
      "     - -------------------------------------- 1.2/42.2 MB 1.3 MB/s eta 0:00:33\n",
      "     - -------------------------------------- 1.3/42.2 MB 1.3 MB/s eta 0:00:32\n",
      "     - -------------------------------------- 1.4/42.2 MB 1.3 MB/s eta 0:00:31\n",
      "     - -------------------------------------- 1.4/42.2 MB 1.3 MB/s eta 0:00:31\n",
      "     - -------------------------------------- 1.6/42.2 MB 1.4 MB/s eta 0:00:30\n",
      "     - -------------------------------------- 1.6/42.2 MB 1.4 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.8/42.2 MB 1.5 MB/s eta 0:00:28\n",
      "     - -------------------------------------- 1.9/42.2 MB 1.5 MB/s eta 0:00:28\n",
      "     - -------------------------------------- 2.0/42.2 MB 1.5 MB/s eta 0:00:27\n",
      "     - -------------------------------------- 2.1/42.2 MB 1.5 MB/s eta 0:00:27\n",
      "     -- ------------------------------------- 2.2/42.2 MB 1.5 MB/s eta 0:00:27\n",
      "     -- ------------------------------------- 2.3/42.2 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.4/42.2 MB 1.6 MB/s eta 0:00:25\n",
      "     -- ------------------------------------- 2.4/42.2 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.5/42.2 MB 1.6 MB/s eta 0:00:26\n",
      "     -- ------------------------------------- 2.6/42.2 MB 1.6 MB/s eta 0:00:25\n",
      "     -- ------------------------------------- 2.7/42.2 MB 1.6 MB/s eta 0:00:25\n",
      "     -- ------------------------------------- 2.9/42.2 MB 1.6 MB/s eta 0:00:24\n",
      "     -- ------------------------------------- 3.0/42.2 MB 1.6 MB/s eta 0:00:24\n",
      "     -- ------------------------------------- 3.1/42.2 MB 1.7 MB/s eta 0:00:24\n",
      "     --- ------------------------------------ 3.2/42.2 MB 1.7 MB/s eta 0:00:24\n",
      "     --- ------------------------------------ 3.4/42.2 MB 1.7 MB/s eta 0:00:23\n",
      "     --- ------------------------------------ 3.4/42.2 MB 1.7 MB/s eta 0:00:23\n",
      "     --- ------------------------------------ 3.6/42.2 MB 1.8 MB/s eta 0:00:22\n",
      "     --- ------------------------------------ 3.8/42.2 MB 1.8 MB/s eta 0:00:22\n",
      "     --- ------------------------------------ 4.0/42.2 MB 1.9 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 4.0/42.2 MB 1.8 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 4.3/42.2 MB 1.9 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 4.4/42.2 MB 1.9 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 4.5/42.2 MB 1.9 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 4.7/42.2 MB 1.9 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 4.8/42.2 MB 2.0 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 5.0/42.2 MB 2.0 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 5.2/42.2 MB 2.0 MB/s eta 0:00:19\n",
      "     ----- ---------------------------------- 5.3/42.2 MB 2.1 MB/s eta 0:00:18\n",
      "     ----- ---------------------------------- 5.5/42.2 MB 2.1 MB/s eta 0:00:18\n",
      "     ----- ---------------------------------- 5.6/42.2 MB 2.1 MB/s eta 0:00:18\n",
      "     ----- ---------------------------------- 5.9/42.2 MB 2.1 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 6.0/42.2 MB 2.2 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 6.2/42.2 MB 2.2 MB/s eta 0:00:17\n",
      "     ------ --------------------------------- 6.3/42.2 MB 2.2 MB/s eta 0:00:17\n",
      "     ------ --------------------------------- 6.5/42.2 MB 2.2 MB/s eta 0:00:17\n",
      "     ------ --------------------------------- 6.8/42.2 MB 2.3 MB/s eta 0:00:16\n",
      "     ------ --------------------------------- 6.9/42.2 MB 2.3 MB/s eta 0:00:16\n",
      "     ------ --------------------------------- 7.1/42.2 MB 2.3 MB/s eta 0:00:16\n",
      "     ------ --------------------------------- 7.3/42.2 MB 2.3 MB/s eta 0:00:15\n",
      "     ------ --------------------------------- 7.4/42.2 MB 2.3 MB/s eta 0:00:15\n",
      "     ------- -------------------------------- 7.5/42.2 MB 2.3 MB/s eta 0:00:15\n",
      "     ------- -------------------------------- 7.9/42.2 MB 2.4 MB/s eta 0:00:15\n",
      "     ------- -------------------------------- 8.0/42.2 MB 2.4 MB/s eta 0:00:15\n",
      "     ------- -------------------------------- 8.2/42.2 MB 2.4 MB/s eta 0:00:14\n",
      "     ------- -------------------------------- 8.3/42.2 MB 2.4 MB/s eta 0:00:14\n",
      "     ------- -------------------------------- 8.3/42.2 MB 2.4 MB/s eta 0:00:15\n",
      "     -------- ------------------------------- 8.5/42.2 MB 2.4 MB/s eta 0:00:15\n",
      "     -------- ------------------------------- 8.6/42.2 MB 2.4 MB/s eta 0:00:14\n",
      "     -------- ------------------------------- 8.8/42.2 MB 2.4 MB/s eta 0:00:14\n",
      "     -------- ------------------------------- 9.0/42.2 MB 2.5 MB/s eta 0:00:14\n",
      "     -------- ------------------------------- 9.3/42.2 MB 2.5 MB/s eta 0:00:14\n",
      "     -------- ------------------------------- 9.4/42.2 MB 2.5 MB/s eta 0:00:14\n",
      "     --------- ------------------------------ 9.7/42.2 MB 2.5 MB/s eta 0:00:13\n",
      "     --------- ------------------------------ 10.0/42.2 MB 2.6 MB/s eta 0:00:13\n",
      "     --------- ------------------------------ 10.2/42.2 MB 2.6 MB/s eta 0:00:13\n",
      "     --------- ------------------------------ 10.5/42.2 MB 2.8 MB/s eta 0:00:12\n",
      "     ---------- ----------------------------- 10.7/42.2 MB 2.9 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 10.8/42.2 MB 2.9 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 11.0/42.2 MB 2.9 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 11.2/42.2 MB 3.0 MB/s eta 0:00:11\n",
      "     ---------- ----------------------------- 11.4/42.2 MB 3.1 MB/s eta 0:00:10\n",
      "     ---------- ----------------------------- 11.6/42.2 MB 3.1 MB/s eta 0:00:10\n",
      "     ----------- ---------------------------- 11.8/42.2 MB 3.2 MB/s eta 0:00:10\n",
      "     ----------- ---------------------------- 12.1/42.2 MB 3.3 MB/s eta 0:00:10\n",
      "     ----------- ---------------------------- 12.3/42.2 MB 3.4 MB/s eta 0:00:09\n",
      "     ----------- ---------------------------- 12.5/42.2 MB 3.4 MB/s eta 0:00:09\n",
      "     ------------ --------------------------- 12.8/42.2 MB 3.5 MB/s eta 0:00:09\n",
      "     ------------ --------------------------- 13.0/42.2 MB 3.6 MB/s eta 0:00:09\n",
      "     ------------ --------------------------- 13.3/42.2 MB 3.7 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 13.5/42.2 MB 3.7 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 13.7/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 13.9/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.1/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.2/42.2 MB 3.9 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.4/42.2 MB 3.9 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.4/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.6/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.7/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 14.9/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.0/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.2/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.4/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.5/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.7/42.2 MB 3.8 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.8/42.2 MB 3.7 MB/s eta 0:00:08\n",
      "     --------------- ------------------------ 16.0/42.2 MB 3.7 MB/s eta 0:00:08\n",
      "     --------------- ------------------------ 16.1/42.2 MB 3.7 MB/s eta 0:00:08\n",
      "     --------------- ------------------------ 16.3/42.2 MB 3.7 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.4/42.2 MB 3.7 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.6/42.2 MB 3.8 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.8/42.2 MB 3.7 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.0/42.2 MB 3.7 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.2/42.2 MB 3.8 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.4/42.2 MB 3.8 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.7/42.2 MB 3.8 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.9/42.2 MB 3.8 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.2/42.2 MB 3.8 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.4/42.2 MB 3.8 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.7/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 19.0/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 19.3/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 19.5/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 19.8/42.2 MB 4.1 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 20.0/42.2 MB 4.1 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 20.2/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 20.4/42.2 MB 4.1 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 20.7/42.2 MB 4.1 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 20.8/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 21.1/42.2 MB 4.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 21.4/42.2 MB 4.1 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 21.5/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 21.8/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 22.0/42.2 MB 4.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 22.3/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 22.4/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 22.6/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 22.8/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 23.1/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 23.2/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 23.4/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 23.7/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 23.8/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 24.0/42.2 MB 3.9 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 24.2/42.2 MB 3.9 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 24.5/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 24.6/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 24.6/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 24.8/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 25.0/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 25.2/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 25.4/42.2 MB 4.1 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 25.5/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 25.7/42.2 MB 4.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 25.9/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 26.0/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 26.2/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 26.4/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 26.6/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 26.8/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 27.0/42.2 MB 4.2 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 27.3/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 27.5/42.2 MB 4.2 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 27.6/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 27.9/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 28.1/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 28.3/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 28.5/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 28.7/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 28.9/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 29.1/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 29.3/42.2 MB 4.0 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 29.6/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 29.8/42.2 MB 4.1 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 30.1/42.2 MB 4.0 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 30.2/42.2 MB 4.0 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 30.4/42.2 MB 4.0 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 30.6/42.2 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 30.8/42.2 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 31.0/42.2 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 31.2/42.2 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 31.3/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 31.4/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 31.5/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 31.7/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 31.9/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 32.1/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 32.4/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 32.6/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 32.8/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 33.1/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 33.3/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 33.6/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 33.8/42.2 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 34.0/42.2 MB 4.0 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 34.3/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 34.5/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 34.6/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 34.8/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 35.1/42.2 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 35.3/42.2 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 35.4/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 35.7/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 35.8/42.2 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.0/42.2 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.1/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.3/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.4/42.2 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.5/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.7/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.9/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.1/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.2/42.2 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.5/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.7/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.9/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.1/42.2 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.3/42.2 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.5/42.2 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.6/42.2 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.8/42.2 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.9/42.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.9/42.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.9/42.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.9/42.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 39.0/42.2 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 39.9/42.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 40.0/42.2 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.2/42.2 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.3/42.2 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.4/42.2 MB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.6/42.2 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.6/42.2 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.7/42.2 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.8/42.2 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.9/42.2 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.1/42.2 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.1/42.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.3/42.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.5/42.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.5/42.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.6/42.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.7/42.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/42.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.1/42.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.2/42.2 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.1-cp38-cp38-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/9.3 MB 4.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/9.3 MB 5.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/9.3 MB 5.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 5.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/9.3 MB 4.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/9.3 MB 4.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.6/9.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.3 MB 4.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.0/9.3 MB 4.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.3/9.3 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.5/9.3 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.7/9.3 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/9.3 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/9.3 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.3/9.3 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.5/9.3 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.6/9.3 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.3 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.0/9.3 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.1/9.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.3/9.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.5/9.3 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.3 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.9/9.3 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.0/9.3 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.1/9.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.3/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.4/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.6/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.8/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.1/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.2/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.4/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.8/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.2/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.5/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.7/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.8/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.3/9.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.5/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 92.2/302.2 kB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  297.0/302.2 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.1 scipy-1.10.1 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057942c",
   "metadata": {},
   "source": [
    "d- Imputation des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f02b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données :\n",
      "       x0      x1\n",
      "0  0.3051     NaN\n",
      "1  0.4949  0.2654\n",
      "2  0.6974  0.2615\n",
      "3  0.3769  0.5846\n",
      "4  0.2231  0.4615\n",
      "5  0.3410  0.8308\n",
      "6  0.4436  0.4962\n",
      "7  0.5897  0.3269\n",
      "8  0.6308  0.5346\n",
      "9  0.5000  0.6731\n",
      "Recherche des valeurs manquantes et remplacement par la moyenne de la colonne\n",
      "Données après imputation par la moyenne :\n",
      "       x0        x1\n",
      "0  0.3051  0.492733\n",
      "1  0.4949  0.265400\n",
      "2  0.6974  0.261500\n",
      "3  0.3769  0.584600\n",
      "4  0.2231  0.461500\n",
      "5  0.3410  0.830800\n",
      "6  0.4436  0.496200\n",
      "7  0.5897  0.326900\n",
      "8  0.6308  0.534600\n",
      "9  0.5000  0.673100\n",
      "\n",
      "Données après imputation par la médiane :\n",
      "       x0      x1\n",
      "0  0.3051  0.4962\n",
      "1  0.4949  0.2654\n",
      "2  0.6974  0.2615\n",
      "3  0.3769  0.5846\n",
      "4  0.2231  0.4615\n",
      "5  0.3410  0.8308\n",
      "6  0.4436  0.4962\n",
      "7  0.5897  0.3269\n",
      "8  0.6308  0.5346\n",
      "9  0.5000  0.6731\n",
      "\n",
      "Données après imputation par la valeur la plus fréquente :\n",
      "       x0      x1\n",
      "0  0.3051  0.2615\n",
      "1  0.4949  0.2654\n",
      "2  0.6974  0.2615\n",
      "3  0.3769  0.5846\n",
      "4  0.2231  0.4615\n",
      "5  0.3410  0.8308\n",
      "6  0.4436  0.4962\n",
      "7  0.5897  0.3269\n",
      "8  0.6308  0.5346\n",
      "9  0.5000  0.6731\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Créer un DataFrame vide\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Créer deux variables x0 et x1. Mettre la première valeur de x1 comme une valeur manquante\n",
    "df['x0'] = [0.3051, 0.4949, 0.6974, 0.3769, 0.2231, 0.341, 0.4436, 0.5897, 0.6308, 0.5]\n",
    "df['x1'] = [np.nan, 0.2654, 0.2615, 0.5846, 0.4615, 0.8308, 0.4962, 0.3269, 0.5346, 0.6731]\n",
    "\n",
    "# Afficher le DataFrame initial\n",
    "print(\"Données :\")\n",
    "print(df)\n",
    "\n",
    "# Créer un objet imputer qui cherche les valeurs 'NaN' et les remplace par la moyenne le long des colonnes (axis=0)\n",
    "print(\"Recherche des valeurs manquantes et remplacement par la moyenne de la colonne\")\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Appliquer l'imputation sur le DataFrame\n",
    "imputed_df = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Afficher le DataFrame après l'imputation\n",
    "print(\"Données après imputation par la moyenne :\")\n",
    "print(imputed_df)\n",
    "\n",
    "# Changer la stratégie d'imputation et analyser les résultats\n",
    "\n",
    "# Stratégie d'imputation par la médiane\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputed_df_median = pd.DataFrame(median_imputer.fit_transform(df), columns=df.columns)\n",
    "print(\"\\nDonnées après imputation par la médiane :\")\n",
    "print(imputed_df_median)\n",
    "\n",
    "# Stratégie d'imputation par la valeur la plus fréquente\n",
    "most_frequent_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputed_df_most_frequent = pd.DataFrame(most_frequent_imputer.fit_transform(df), columns=df.columns)\n",
    "print(\"\\nDonnées après imputation par la valeur la plus fréquente :\")\n",
    "print(imputed_df_most_frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9922f",
   "metadata": {},
   "source": [
    "e- Sorting et Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59342f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe initial :\n",
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  1  2  3\n",
      "2  2  3  4\n",
      "3  3  5  1\n",
      "4  3  4  1\n",
      "5  5  2  2\n",
      "6  4  5  3\n",
      "\n",
      "Le jeu de données est trié selon la colonne 'A' :\n",
      "   A  B  C\n",
      "1  1  2  3\n",
      "0  2  1  5\n",
      "2  2  3  4\n",
      "3  3  5  1\n",
      "4  3  4  1\n",
      "6  4  5  3\n",
      "5  5  2  2\n",
      "\n",
      "Le jeu de données est mélangé :\n",
      "   A  B  C\n",
      "0  5  2  2\n",
      "1  2  3  4\n",
      "2  2  1  5\n",
      "3  3  4  1\n",
      "4  4  5  3\n",
      "5  3  5  1\n",
      "6  1  2  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Création du DataFrame initial\n",
    "df = pd.DataFrame({'A': [2,1,2,3,3,5,4],'B': [1,2,3,5,4,2,5], 'C': [5,3,4,1,1,2,3]})\n",
    "print(\"Dataframe initial :\")\n",
    "print(df)\n",
    "\n",
    "# Tri du DataFrame en fonction de la colonne 'A'\n",
    "print(\"\\nLe jeu de données est trié selon la colonne 'A' :\")\n",
    "df = df.sort_values(by='A', ascending=True)\n",
    "print(df)\n",
    "\n",
    "# Mélange aléatoire des données du DataFrame\n",
    "print(\"\\nLe jeu de données est mélangé :\")\n",
    "index = df.index.tolist()\n",
    "np.random.shuffle(index)\n",
    "df = df.iloc[index]\n",
    "\n",
    "# Réinitialisation de l'indice pour refléter le nouveau DataFrame mélangé\n",
    "df = df.reset_index(drop=True)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2445b10",
   "metadata": {},
   "source": [
    "2- Transformation des données\n",
    "a- Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f53c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données :\n",
      "    constructor          Model  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  PRP  \\\n",
      "0       adviser          32/60   125   256   6000   256     16    128  198   \n",
      "1        amdahl         470v/7    29  8000  32000    32      8     32  269   \n",
      "2        amdahl        470v/7a    29  8000  32000    32      8     32  220   \n",
      "3        amdahl        470v/7b    29  8000  32000    32      8     32  172   \n",
      "4        amdahl        470v/7c    29  8000  16000    32      8     16  132   \n",
      "..          ...            ...   ...   ...    ...   ...    ...    ...  ...   \n",
      "204      sperry           80/8   124  1000   8000     0      1      8   42   \n",
      "205      sperry  90/80-model-3    98  1000   8000    32      2      8   46   \n",
      "206      sratus             32   125  2000   8000     0      2     14   52   \n",
      "207        wang         vs-100   480   512   8000    32      0      0   67   \n",
      "208        wang          vs-90   480  1000   4000     0      0      0   45   \n",
      "\n",
      "     ERP  \n",
      "0    199  \n",
      "1    253  \n",
      "2    253  \n",
      "3    253  \n",
      "4    132  \n",
      "..   ...  \n",
      "204   37  \n",
      "205   50  \n",
      "206   41  \n",
      "207   47  \n",
      "208   25  \n",
      "\n",
      "[209 rows x 10 columns]\n",
      "\n",
      "********** Normalisation Min-Max *********\n",
      "\n",
      "Moyenne après la normalisation :\n",
      "MYCT=0.13, MMAX=0.18\n",
      "\n",
      "\n",
      "Valeur minimale et maximale pour la feature MYCT après la normalisation : \n",
      "MIN=0.00, MAX=1.00\n",
      "\n",
      "\n",
      "Valeur minimale et maximale pour la feature MMAX après la normalisation : \n",
      "MIN=0.00, MAX=1.00\n",
      "\n",
      "Données après normalisation Min-Max :\n",
      "    constructor          Model      MYCT  MMIN      MMAX  CACH  CHMIN  CHMAX  \\\n",
      "0       adviser          32/60  0.072825   256  0.092843   256     16    128   \n",
      "1        amdahl         470v/7  0.008092  8000  0.499499    32      8     32   \n",
      "2        amdahl        470v/7a  0.008092  8000  0.499499    32      8     32   \n",
      "3        amdahl        470v/7b  0.008092  8000  0.499499    32      8     32   \n",
      "4        amdahl        470v/7c  0.008092  8000  0.249249    32      8     16   \n",
      "..          ...            ...       ...   ...       ...   ...    ...    ...   \n",
      "204      sperry           80/8  0.072151  1000  0.124124     0      1      8   \n",
      "205      sperry  90/80-model-3  0.054619  1000  0.124124    32      2      8   \n",
      "206      sratus             32  0.072825  2000  0.124124     0      2     14   \n",
      "207        wang         vs-100  0.312205   512  0.124124    32      0      0   \n",
      "208        wang          vs-90  0.312205  1000  0.061562     0      0      0   \n",
      "\n",
      "     PRP  ERP  \n",
      "0    198  199  \n",
      "1    269  253  \n",
      "2    220  253  \n",
      "3    172  253  \n",
      "4    132  132  \n",
      "..   ...  ...  \n",
      "204   42   37  \n",
      "205   46   50  \n",
      "206   52   41  \n",
      "207   67   47  \n",
      "208   45   25  \n",
      "\n",
      "[209 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Définir l'URL du jeu de données et les noms de colonnes\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/cpu-performance/machine.data'\n",
    "names = ['constructor', 'Model', 'MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP', 'ERP']\n",
    "\n",
    "# Lire le jeu de données depuis l'URL\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "\n",
    "# Afficher le jeu de données initial\n",
    "print(\"Données :\")\n",
    "print(dataset)\n",
    "\n",
    "# Créer un objet MinMaxScaler pour normaliser MYCT et MMAX\n",
    "minmax_scale = MinMaxScaler()\n",
    "\n",
    "# Appliquer la normalisation Min-Max à MYCT et MMAX\n",
    "dataset[['MYCT', 'MMAX']] = minmax_scale.fit_transform(dataset[['MYCT', 'MMAX']])\n",
    "\n",
    "# Afficher les statistiques après la normalisation\n",
    "print(\"\\n********** Normalisation Min-Max *********\\n\")\n",
    "print('Moyenne après la normalisation :\\nMYCT={:.2f}, MMAX={:.2f}'\n",
    "      .format(dataset['MYCT'].mean(), dataset['MMAX'].mean()))\n",
    "print('\\n')\n",
    "print('Valeur minimale et maximale pour la feature MYCT après la normalisation : \\nMIN={:.2f}, MAX={:.2f}'\n",
    "      .format(dataset['MYCT'].min(), dataset['MYCT'].max()))\n",
    "print('\\n')\n",
    "print('Valeur minimale et maximale pour la feature MMAX après la normalisation : \\nMIN={:.2f}, MAX={:.2f}'\n",
    "      .format(dataset['MMAX'].min(), dataset['MMAX'].max()))\n",
    "\n",
    "# Afficher le DataFrame après la normalisation\n",
    "print(\"\\nDonnées après normalisation Min-Max :\")\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d984932",
   "metadata": {},
   "source": [
    "b- Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1ef3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données :\n",
      "    constructor          Model  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  PRP  \\\n",
      "0       adviser          32/60   125   256   6000   256     16    128  198   \n",
      "1        amdahl         470v/7    29  8000  32000    32      8     32  269   \n",
      "2        amdahl        470v/7a    29  8000  32000    32      8     32  220   \n",
      "3        amdahl        470v/7b    29  8000  32000    32      8     32  172   \n",
      "4        amdahl        470v/7c    29  8000  16000    32      8     16  132   \n",
      "..          ...            ...   ...   ...    ...   ...    ...    ...  ...   \n",
      "204      sperry           80/8   124  1000   8000     0      1      8   42   \n",
      "205      sperry  90/80-model-3    98  1000   8000    32      2      8   46   \n",
      "206      sratus             32   125  2000   8000     0      2     14   52   \n",
      "207        wang         vs-100   480   512   8000    32      0      0   67   \n",
      "208        wang          vs-90   480  1000   4000     0      0      0   45   \n",
      "\n",
      "     ERP  \n",
      "0    199  \n",
      "1    253  \n",
      "2    253  \n",
      "3    253  \n",
      "4    132  \n",
      "..   ...  \n",
      "204   37  \n",
      "205   50  \n",
      "206   41  \n",
      "207   47  \n",
      "208   25  \n",
      "\n",
      "[209 rows x 10 columns]\n",
      "\n",
      "********** Standardisation (Z-Score) *********\n",
      "\n",
      "Moyenne et Écart type après la standardisation de la feature MYCT :\n",
      "MYCT Moyenne : -0.00, Écart type : 1.00\n",
      "\n",
      "\n",
      "Moyenne et Écart type après la standardisation de la feature MMAX :\n",
      "MMAX Moyenne : 0.00, Écart type : 1.00\n",
      "\n",
      "Affichage des valeurs après la standardisation (Z-Score) :\n",
      "    constructor          Model      MYCT  MMIN      MMAX  CACH  CHMIN  CHMAX  \\\n",
      "0       adviser          32/60 -0.303586   256 -0.495462   256     16    128   \n",
      "1        amdahl         470v/7 -0.673330  8000  1.727049    32      8     32   \n",
      "2        amdahl        470v/7a -0.673330  8000  1.727049    32      8     32   \n",
      "3        amdahl        470v/7b -0.673330  8000  1.727049    32      8     32   \n",
      "4        amdahl        470v/7c -0.673330  8000  0.359350    32      8     16   \n",
      "..          ...            ...       ...   ...       ...   ...    ...    ...   \n",
      "204      sperry           80/8 -0.307438  1000 -0.324500     0      1      8   \n",
      "205      sperry  90/80-model-3 -0.407576  1000 -0.324500    32      2      8   \n",
      "206      sratus             32 -0.303586  2000 -0.324500     0      2     14   \n",
      "207        wang         vs-100  1.063694   512 -0.324500    32      0      0   \n",
      "208        wang          vs-90  1.063694  1000 -0.666425     0      0      0   \n",
      "\n",
      "     PRP  ERP  \n",
      "0    198  199  \n",
      "1    269  253  \n",
      "2    220  253  \n",
      "3    172  253  \n",
      "4    132  132  \n",
      "..   ...  ...  \n",
      "204   42   37  \n",
      "205   46   50  \n",
      "206   52   41  \n",
      "207   67   47  \n",
      "208   45   25  \n",
      "\n",
      "[209 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Définir l'URL du jeu de données et les noms de colonnes\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/cpu-performance/machine.data'\n",
    "names = ['constructor', 'Model', 'MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP', 'ERP']\n",
    "\n",
    "# Lire le jeu de données depuis l'URL\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "\n",
    "# Afficher le jeu de données initial\n",
    "print(\"Données :\")\n",
    "print(dataset)\n",
    "\n",
    "# Créer un objet StandardScaler pour la standardisation des colonnes\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "# Appliquer la standardisation aux colonnes MYCT et MMAX\n",
    "dataset[['MYCT', 'MMAX']] = std_scaler.fit_transform(dataset[['MYCT', 'MMAX']])\n",
    "\n",
    "# Afficher les statistiques après la standardisation\n",
    "print(\"\\n********** Standardisation (Z-Score) *********\\n\")\n",
    "print('Moyenne et Écart type après la standardisation de la feature MYCT :')\n",
    "print('MYCT Moyenne : {:.2f}, Écart type : {:.2f}'.format(dataset['MYCT'].mean(), dataset['MYCT'].std()))\n",
    "print('\\n')\n",
    "print('Moyenne et Écart type après la standardisation de la feature MMAX :')\n",
    "print('MMAX Moyenne : {:.2f}, Écart type : {:.2f}'.format(dataset['MMAX'].mean(), dataset['MMAX'].std()))\n",
    "\n",
    "# Afficher le DataFrame après la standardisation\n",
    "print('\\nAffichage des valeurs après la standardisation (Z-Score) :')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d7df3",
   "metadata": {},
   "source": [
    "3- Reduction des données\n",
    "a- Les variables catégorielles (qualitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d199dfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Blue\n",
      "1      Red\n",
      "2    Green\n",
      "dtype: category\n",
      "Categories (3, object): ['Blue', 'Green', 'Red']\n",
      "0      NaN\n",
      "1    Green\n",
      "2      Red\n",
      "3     Blue\n",
      "4      NaN\n",
      "dtype: category\n",
      "Categories (3, object): ['Blue', 'Green', 'Red']\n",
      "0    True\n",
      "4    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'],\n",
    "dtype='category')\n",
    "car_data = pd.Series(\n",
    "pd.Categorical(['Yellow', 'Green', 'Red', 'Blue',\n",
    "'Purple'],\n",
    "categories=car_colors, ordered=False))\n",
    "find_entries = pd.isnull(car_data)\n",
    "print(car_colors)\n",
    "print\n",
    "print(car_data)\n",
    "print\n",
    "print(find_entries[find_entries == True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002abe2d",
   "metadata": {},
   "source": [
    "b- Combinaison des catégories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87c7ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Série car_data après combinaison des catégories :\n",
      "0        Blue\n",
      "1       Green\n",
      "2    Blue_Red\n",
      "3       Green\n",
      "4    Blue_Red\n",
      "5       Green\n",
      "dtype: category\n",
      "Categories (4, object): ['Blue', 'Green', 'Red', 'Blue_Red']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Créer une variable catégorielle car_colors avec des couleurs\n",
    "car_colors = pd.Series(['Blue', 'Green', 'Red'], dtype='category')\n",
    "\n",
    "# Créer une série car_data avec des couleurs de voitures\n",
    "car_data = pd.Series(pd.Categorical(\n",
    "    ['Blue', 'Green', 'Red', 'Green', 'Red', 'Green'],\n",
    "    categories=car_colors, ordered=False\n",
    "))\n",
    "\n",
    "# Ajouter la catégorie \"Blue_Red\" aux catégories existantes\n",
    "car_data = car_data.cat.add_categories(\"Blue_Red\")\n",
    "\n",
    "# Remplacer les entrées de couleur \"Red\" par \"Blue_Red\"\n",
    "car_data.loc[car_data.isin(['Red'])] = 'Blue_Red'\n",
    "\n",
    "# Afficher la série car_data après la combinaison des catégories\n",
    "print(\"Série car_data après combinaison des catégories :\")\n",
    "print(car_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0bfd76",
   "metadata": {},
   "source": [
    "c- Concaténation et transformation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19be96b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame après ajout :\n",
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "3  4  4  4\n",
      "\n",
      "DataFrame après ajout de la nouvelle ligne :\n",
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "3  4  4  4\n",
      "4  5  5  5\n",
      "\n",
      "DataFrame après ajout de la colonne 'D' :\n",
      "   A  B  C  D\n",
      "0  2  1  5  1\n",
      "1  3  2  3  2\n",
      "2  1  3  4  3\n",
      "3  4  4  4  4\n",
      "4  5  5  5  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Créer un DataFrame df\n",
    "df = pd.DataFrame({'A': [2, 3, 1], 'B': [1, 2, 3], 'C': [5, 3, 4]})\n",
    "\n",
    "# Créer un DataFrame df1 à ajouter\n",
    "df1 = pd.DataFrame({'A': [4], 'B': [4], 'C': [4]})\n",
    "\n",
    "# Utiliser la méthode concat pour ajouter df1 à df\n",
    "df = pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "# Afficher le DataFrame après l'ajout\n",
    "print(\"DataFrame après ajout :\")\n",
    "print(df)\n",
    "\n",
    "# Ajouter une nouvelle ligne de données\n",
    "df.loc[df.last_valid_index() + 1] = [5, 5, 5]\n",
    "\n",
    "# Afficher le DataFrame après l'ajout de la nouvelle ligne\n",
    "print(\"\\nDataFrame après ajout de la nouvelle ligne :\")\n",
    "print(df)\n",
    "\n",
    "# Créer un DataFrame df2 avec une nouvelle colonne 'D'\n",
    "df2 = pd.DataFrame({'D': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Utiliser la méthode concat pour ajouter la colonne 'D' à df\n",
    "df = pd.concat([df, df2], axis=1)\n",
    "\n",
    "# Afficher le DataFrame final après l'ajout de la colonne 'D'\n",
    "print(\"\\nDataFrame après ajout de la colonne 'D' :\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf759e45",
   "metadata": {},
   "source": [
    "d- Agrégation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "799864d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Map  Values  Sum  Moy\n",
      "0    0       1    6  2.0\n",
      "1    0       2    6  2.0\n",
      "2    0       3    6  2.0\n",
      "3    1       5    9  4.5\n",
      "4    1       4    9  4.5\n",
      "5    2       2    7  3.5\n",
      "6    2       5    7  3.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Création d'un DataFrame avec des colonnes 'Map' et 'Values'\n",
    "df = pd.DataFrame({'Map': [0,0,0,1,1,2,2], 'Values': [1,2,3,5,4,2,5]})\n",
    "\n",
    "# Utilisation de la méthode groupby pour regrouper les valeurs par la colonne 'Map'\n",
    "# Utilisation de la fonction d'agrégation np.sum pour calculer la somme des valeurs pour chaque groupe 'Map'\n",
    "# La méthode transform applique la somme à chaque groupe 'Map'\n",
    "df['Sum'] = df.groupby('Map')['Values'].transform(np.sum)\n",
    "\n",
    "# Utilisation de la méthode groupby pour regrouper les valeurs par la colonne 'Map'\n",
    "# Utilisation de la fonction d'agrégation np.mean pour calculer la moyenne des valeurs pour chaque groupe 'Map'\n",
    "# La méthode transform applique la moyenne à chaque groupe 'Map'\n",
    "df['Moy'] = df.groupby('Map')['Values'].transform(np.mean)\n",
    "\n",
    "# Affichage du DataFrame résultant\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f01d91",
   "metadata": {},
   "source": [
    "e. Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7428b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category_A  category_B  category_C\n",
      "0        True       False       False\n",
      "1       False        True       False\n",
      "2       False       False        True\n",
      "3        True       False       False\n",
      "4       False        True       False\n",
      "5       False       False        True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Définition d'un DataFrame avec des variables catégoriques\n",
    "data = {'category': ['A', 'B', 'C', 'A', 'B', 'C']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Transformation des données catégoriques en variables indicatrices\n",
    "df_encoded = pd.get_dummies(df, columns=['category'], prefix=['category'])\n",
    "\n",
    "# Affichage du DataFrame\n",
    "print(df_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4dd509",
   "metadata": {},
   "source": [
    "4- Discrétisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0459f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS data values:\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "    sepal_length_category  \n",
      "0                     Low  \n",
      "1                     Low  \n",
      "2                     Low  \n",
      "3                     Low  \n",
      "4                     Low  \n",
      "..                    ...  \n",
      "145                  High  \n",
      "146                Medium  \n",
      "147                  High  \n",
      "148                Medium  \n",
      "149                Medium  \n",
      "\n",
      "[150 rows x 5 columns]\n",
      "\n",
      "Quantiles:\n",
      "      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0.00                4.3               2.0               1.00               0.1\n",
      "0.25                5.1               2.8               1.60               0.3\n",
      "0.50                5.8               3.0               4.35               1.3\n",
      "0.75                6.4               3.3               5.10               1.8\n",
      "1.00                7.9               4.4               6.90               2.5\n",
      "\n",
      "Binning Iris Data:\n",
      "     sepal length (cm) sepal_length_category\n",
      "0                  5.1                   Low\n",
      "1                  4.9                   Low\n",
      "2                  4.7                   Low\n",
      "3                  4.6                   Low\n",
      "4                  5.0                   Low\n",
      "..                 ...                   ...\n",
      "145                6.7                  High\n",
      "146                6.3                Medium\n",
      "147                6.5                  High\n",
      "148                6.2                Medium\n",
      "149                5.9                Medium\n",
      "\n",
      "[150 rows x 2 columns]\n",
      "\n",
      "Frequency in each category:\n",
      "sepal_length_category\n",
      "Medium    56\n",
      "Low       52\n",
      "High      42\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le jeu de données Iris\n",
    "iris = load_iris()\n",
    "iris_dataframe = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Discrétisation basée sur des effectifs égaux (ou quantiles)\n",
    "quantiles = np.array([0, 0.25, 0.50, 0.75, 1])\n",
    "quantile_values = iris_dataframe.quantile(quantiles, axis=0)\n",
    "\n",
    "# Le binning transforme les variables numériques en variables catégoriques\n",
    "iris_binned = pd.qcut(iris_dataframe['sepal length (cm)'], q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "iris_dataframe['sepal_length_category'] = iris_binned\n",
    "\n",
    "# Obtenir une fréquence pour chaque variable catégorique de l'ensemble de données\n",
    "category_counts = iris_dataframe['sepal_length_category'].value_counts()\n",
    "\n",
    "# Afficher les statistiques\n",
    "print(\"IRIS data values:\")\n",
    "print(iris_dataframe)\n",
    "print(\"\\nQuantiles:\")\n",
    "print(quantile_values)\n",
    "print(\"\\nBinning Iris Data:\")\n",
    "print(iris_dataframe[['sepal length (cm)', 'sepal_length_category']])\n",
    "print(\"\\nFrequency in each category:\")\n",
    "print(category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb997a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
